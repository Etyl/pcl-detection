{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQRW0ws09Fqn"
      },
      "source": [
        "# Imports + GPU Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3osGRJB9Fqo",
        "outputId": "0b05beff-b579-46da-ab10-c3160adc0d0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /home/infres/hverninas-22/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/infres/hverninas-22/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import logging\n",
        "import re\n",
        "import nltk\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from copy import deepcopy\n",
        "from urllib import request\n",
        "from dont_patronize_me import DontPatronizeMe # data manager module\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "\n",
        "from preprocessing import load_data, preprocess_data, DPMDataset\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'device: {device}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMLFfJf39Fqp"
      },
      "source": [
        "# Data Setup\n",
        "\n",
        "Retrieves the data, applies the specified train and test split to organise data into **train_df** and **dev_df**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8JhqkAx9Fqp",
        "outputId": "dbe3f11e-31e8-40c1-bb94-ca90dec4dfb0"
      },
      "outputs": [],
      "source": [
        "train_df, dev_df, test_df = load_data()\n",
        "\n",
        "# downsample negative instances\n",
        "pcldf = train_df[train_df.label==1]\n",
        "npos = len(pcldf)\n",
        "balanced_train_df = pd.concat([pcldf, train_df[train_df.label==0][:int(2.5*npos)]])\n",
        "balanced_train_df = balanced_train_df[['text', 'community', 'label', 'country']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53rjPgc49Fqp"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_train_df = preprocess_data(balanced_train_df, clean_data=False, augment_data=True, add_country=False, add_community=True)\n",
        "processed_dev_df = preprocess_data(dev_df, clean_data=False, add_country=False, add_community=True)\n",
        "processed_test_df = preprocess_data(test_df, clean_data=False, add_country=False, add_community=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import RobertaPreTrainedModel, TrainingArguments, DebertaModel,DebertaPreTrainedModel\n",
        "\n",
        "class PoolingHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.pooling = nn.AdaptiveMaxPool1d(1)  # Global Max Pooling\n",
        "        self.projection =nn.Sequential(\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.Linear(config.hidden_size,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        deberta_output_permuted = x.permute(0, 2, 1)  # Change the shape for pooling\n",
        "        pooled_output = self.pooling(deberta_output_permuted).squeeze(-1)  # Apply pooling\n",
        "        logits = self.projection(pooled_output)  # Projection layer\n",
        "        return logits\n",
        "    \n",
        "class CLSHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.projection =nn.Sequential(\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.Linear(config.hidden_size,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x[:,0,:]\n",
        "        logits = self.projection(x)  # Projection layer\n",
        "        return logits\n",
        "\n",
        "class DebertaClassification(DebertaPreTrainedModel):\n",
        "    \"\"\"\n",
        "    Implementation of Deberta with a classifier head\n",
        "    \"\"\"\n",
        "    def __init__(self,config):\n",
        "\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.deberta = DebertaModel(config)\n",
        "        self.head = CLSHead(config)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        inputs_embeds=None,\n",
        "        target=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None):\n",
        "        \n",
        "        deberta_output = self.deberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )[0]\n",
        "        logits = self.head(deberta_output)\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAINING LOOP FOR TRAINING DEBERTA \n",
        "from transformers import Trainer, TrainingArguments, DebertaTokenizer, RobertaTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class Trainer_PCL(Trainer):\n",
        "\n",
        "    def __init__( \n",
        "        self,\n",
        "        **kwargs\n",
        "        ):\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "        \n",
        "        self.epoch = 1\n",
        "        self.results = {}\n",
        "\n",
        "\n",
        "    def compute_loss(self, model, inputs, num_items_in_batch=None):\n",
        "        \n",
        "        outputs = model(**inputs).view(-1)\n",
        "\n",
        "        loss_fn = nn.BCELoss()\n",
        "        target = inputs['target'].float()\n",
        "        loss = loss_fn(outputs, target)\n",
        "        return loss\n",
        "    \n",
        "    # Custom Evaluation \n",
        "    def evaluate(self, evaluate_datset=None, ignore_keys=None, metric_key_prefix='eval'):\n",
        "        \n",
        "        if self.epoch < 10:\n",
        "            self.epoch+=1\n",
        "            return\n",
        "        preds = []\n",
        "        labels = []\n",
        "\n",
        "        eval_dataloader = super().get_test_dataloader(self.eval_dataset)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data in tqdm(eval_dataloader):\n",
        "                \n",
        "                output = self.model(**data)\n",
        "                pred = torch.max(output, 1)[1]\n",
        "            \n",
        "                preds.extend(pred.cpu().tolist())\n",
        "                labels.extend(data['target'].cpu().tolist())\n",
        "\n",
        "        # with the saved predictions and labels we can compute accuracy, precision, recall and f1-score\n",
        "        metrics = compute_metrics((preds, labels))\n",
        "        print(metrics)\n",
        "\n",
        "        self.results[self.epoch] = metrics\n",
        "        self.epoch += 1       \n",
        "\n",
        "            \n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    report = classification_report(preds, labels, target_names=[\"Not PCL\",\"PCL\"], output_dict= True) \n",
        "\n",
        "    return {\"f1\": report['PCL']['f1-score'],\n",
        "            \"precision\": report['PCL']['precision'],\n",
        "            \"recall\": report['PCL']['recall']\n",
        "            }\n",
        "\n",
        "def train(model, data, num_epochs, lr=0.0001, optimizer=None, lr_scheduler=None):\n",
        "\n",
        "    data = data.reset_index(drop=True)\n",
        "    \n",
        "    tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
        "    train_dataset = DPMDataset(data, tokenizer, max_len=128)\n",
        "\n",
        "    Training_args = TrainingArguments(\n",
        "        output_dir=\"test_trainer\",\n",
        "        learning_rate=lr,\n",
        "        logging_steps=100,\n",
        "        per_device_train_batch_size=8,\n",
        "        num_train_epochs=num_epochs,\n",
        "        remove_unused_columns=False,\n",
        "        logging_dir='./logs', \n",
        "    )\n",
        "    \n",
        "    trainer = Trainer_PCL(\n",
        "        model = model,\n",
        "        args = Training_args,\n",
        "        train_dataset = train_dataset,\n",
        "        # eval_dataset = eval_dataset,\n",
        "        data_collator= train_dataset.collate_fn,\n",
        "        optimizers = (optimizer, lr_scheduler),\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model('deberta-finetuned')\n",
        "    return trainer.results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate(model, tokenizer, data_df):\n",
        "\n",
        "    text_input = data_df[\"text\"].tolist()\n",
        "\n",
        "    encodings = tokenizer(text_input, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        output = model(**encodings)\n",
        "        preds = torch.round(output).tolist()\n",
        "\n",
        "    labels = data_df[\"label\"].tolist()\n",
        "\n",
        "    return f1_score(labels,preds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_seed(i):\n",
        "    torch.manual_seed(i)\n",
        "    np.random.seed(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DebertaClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['head.projection.1.bias', 'head.projection.1.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'augmented_train_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr)\n\u001b[1;32m     11\u001b[0m lrs \u001b[38;5;241m=\u001b[39m lr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m results \u001b[38;5;241m=\u001b[39m train(model, \u001b[43maugmented_train_df\u001b[49m, num_epochs\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, lr\u001b[38;5;241m=\u001b[39mlr, optimizer\u001b[38;5;241m=\u001b[39moptimizer, lr_scheduler\u001b[38;5;241m=\u001b[39mlrs)\n\u001b[1;32m     15\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m DebertaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicrosoft/deberta-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m score \u001b[38;5;241m=\u001b[39m evaluate(model, tokenizer, dev_df)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'augmented_train_df' is not defined"
          ]
        }
      ],
      "source": [
        "scores = []\n",
        "\n",
        "for i in range(5):\n",
        "    set_seed(i)\n",
        "\n",
        "    # model = JoBert.from_pretrained('FacebookAI/roberta-base').to(device)\n",
        "    model = DebertaClassification.from_pretrained('microsoft/deberta-base').to(device)\n",
        "\n",
        "    lr = 1e-5\n",
        "    optimizer = optim.AdamW(model.parameters(), lr)\n",
        "    lrs = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "    \n",
        "    results = train(model, processed_train_df, num_epochs= 5, lr=lr, optimizer=optimizer, lr_scheduler=lrs)\n",
        "\n",
        "    tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
        "\n",
        "    score = evaluate(model, tokenizer, processed_dev_df)\n",
        "    scores.append(score)\n",
        "\n",
        "print(scores)\n",
        "print(np.mean(scores))\n",
        "print(np.std(scores))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
