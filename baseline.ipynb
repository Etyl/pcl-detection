{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports + GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from copy import deepcopy\n",
    "from urllib import request\n",
    "from dont_patronize_me import DontPatronizeMe # data manager module\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "from preprocessing import load_data, preprocess_data, DPMDataset\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA A100 80GB PCIe MIG 1g.10gb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = load_data()\n",
    "\n",
    "# downsample negative instances\n",
    "pcldf = train_df[train_df.label==1]\n",
    "npos = len(pcldf)\n",
    "balanced_train_df = pd.concat([pcldf, train_df[train_df.label==0][:int(2.5*npos)]])\n",
    "balanced_train_df = balanced_train_df[['text', 'community', 'label', 'country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_df = preprocess_data(balanced_train_df, clean_data=False, augment_data=False, add_country=False, add_community=False)\n",
    "processed_dev_df = preprocess_data(dev_df, clean_data=False, add_country=False, add_community=False)\n",
    "processed_test_df = preprocess_data(test_df, clean_data=False, add_country=False, add_community=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF with logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score with TF-IDF: 0.3755\n",
      "\n",
      "Example of misclassified text:\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \\\n",
      "1249  The casting was gut-punchingly faithful and , with very few exceptions , matched up with the pictures in my head , the story stayed true , and somehow managed to unfold in a way that entirely satisfied the vast majority of those who loved the books without leaving those who had n't ( yet ) done so hopelessly lost . It was a Hollywood miracle -- and finally , I had the ultimate challenge for those still wary of the written word : Watch the series , and then tell me you do n't want to know what happens next . I dare you .   \n",
      "\n",
      "      label  \n",
      "1249      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Data\n",
    "X_train, y_train = processed_train_df[\"text\"], processed_train_df[\"label\"]\n",
    "X_dev, y_dev = processed_dev_df[\"text\"], processed_dev_df[\"label\"]\n",
    "\n",
    "# Transform text in BoW\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=10000)  \n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_dev_tfidf = vectorizer.transform(X_dev)\n",
    "\n",
    "# Logistic regression\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = logreg.predict(X_dev_tfidf)\n",
    "f1_tfidf = f1_score(y_dev, y_pred)\n",
    "print(f\"F1 Score with TF-IDF: {f1_tfidf:.4f}\")\n",
    "\n",
    "# Find misclassified examples\n",
    "misclassified = processed_dev_df.iloc[(y_pred != y_dev).to_numpy()]\n",
    "\n",
    "# Print one example\n",
    "example = misclassified.sample(1, random_state=42)\n",
    "print(\"\\nExample of misclassified text:\")\n",
    "print(example[[\"text\", \"label\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score with SVM: 0.3871\n",
      "\n",
      "Example of misclassified text:\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \\\n",
      "1249  The casting was gut-punchingly faithful and , with very few exceptions , matched up with the pictures in my head , the story stayed true , and somehow managed to unfold in a way that entirely satisfied the vast majority of those who loved the books without leaving those who had n't ( yet ) done so hopelessly lost . It was a Hollywood miracle -- and finally , I had the ultimate challenge for those still wary of the written word : Watch the series , and then tell me you do n't want to know what happens next . I dare you .   \n",
      "\n",
      "      label  \n",
      "1249      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Data\n",
    "X_train, y_train = processed_train_df[\"text\"], processed_train_df[\"label\"]\n",
    "X_dev, y_dev = processed_dev_df[\"text\"], processed_dev_df[\"label\"]\n",
    "\n",
    "# Transform text in BoW\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=10000)  \n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_dev_tfidf = vectorizer.transform(X_dev)\n",
    "\n",
    "# SVM model\n",
    "svm_model = LinearSVC(class_weight=\"balanced\", random_state=42)\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_svm = svm_model.predict(X_dev_tfidf)\n",
    "f1_svm = f1_score(y_dev, y_pred_svm)\n",
    "print(f\"F1 Score with SVM: {f1_svm:.4f}\")\n",
    "\n",
    "# Find misclassified examples\n",
    "misclassified = processed_dev_df.iloc[(y_pred != y_dev).to_numpy()]\n",
    "\n",
    "# Print one example\n",
    "example = misclassified.sample(1, random_state=42)\n",
    "print(\"\\nExample of misclassified text:\")\n",
    "print(example[[\"text\", \"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Top 20 Bigrams in False Positives:**\n",
      "poor families: 6.58\n",
      "homeless people: 2.29\n",
      "children poor: 1.28\n",
      "young people: 1.25\n",
      "vulnerable children: 1.12\n",
      "homeless man: 1.12\n",
      "year old: 1.11\n",
      "come poor: 1.06\n",
      "homeless person: 1.03\n",
      "disabled children: 0.99\n",
      "women children: 0.96\n",
      "people need: 0.94\n",
      "refugee camps: 0.89\n",
      "men women: 0.87\n",
      "asylum seekers: 0.85\n",
      "years ago: 0.84\n",
      "hopeless situation: 0.82\n",
      "illegal immigrants: 0.79\n",
      "help need: 0.79\n",
      "disabled people: 0.78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "# Identify false positives (FPs) where the model predicted PCL but the true label is 0\n",
    "false_positives = processed_dev_df[(y_pred_svm == 1) & (y_dev == 0)][\"text\"]\n",
    "\n",
    "# Vectorizer setup for bigrams\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2), stop_words=\"english\", max_features=5000)\n",
    "X_fp_tfidf = vectorizer.fit_transform(false_positives)\n",
    "\n",
    "# Get bigram feature names\n",
    "bigram_features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert TF-IDF matrix to a frequency count\n",
    "word_counts = np.asarray(X_fp_tfidf.sum(axis=0)).flatten()\n",
    "\n",
    "# Create a dictionary of bigram -> count\n",
    "bigram_freq = dict(zip(bigram_features, word_counts))\n",
    "\n",
    "# Sort bigrams by frequency\n",
    "sorted_bigrams = sorted(bigram_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the top 20 bigrams\n",
    "print(\"\\n**Top 20 Bigrams in False Positives:**\")\n",
    "for bigram, count in sorted_bigrams[:20]:\n",
    "    print(f\"{bigram}: {count:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
